---
title: 'Hidden Parameter Recurrent State Space Models For Changing Dynamics Scenarios'
collection: publications
permalink: /publication/hiprssm
date: 2022-06-29
venue: 'International Conference on Learning Representations (ICLR 2022)'
authors: 'Vaisakh Shaj Kumar, D BÃ¼chler, R Sonker, <b>Philipp Becker</b>, Gerhard Neumann'
paperurl: 'https://arxiv.org/pdf/2206.14697'
codeurl: 'https://github.com/ALRhub/HiP-RSSM'
#codeurl: 'https://github.com/Onur4229/SVSL_LMOE'
#slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
#paperurl: 'http://academicpages.github.io/files/paper1.pdf'
#citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---

<p>
<h3> Abstract: </h3>
Recurrent State-space models (RSSMs) are highly expressive models for learning patterns in time series data and system identification. However, these models assume that the dynamics are fixed and unchanging, which is rarely the case in real-world scenarios. Many control applications often exhibit tasks with similar but not identical dynamics which can be modeled as a latent variable. We introduce the Hidden Parameter Recurrent State Space Models (HiP-RSSMs), a framework that parametrizes a family of related dynamical systems with a low-dimensional set of latent factors. We present a simple and effective way of learning and performing inference over this Gaussian graphical model that avoids approximations like variational inference. We show that HiP-RSSMs outperforms RSSMs and competing multi-task models on several challenging robotic benchmarks both on real-world systems and simulations.
</p>